Sources:
https://gotimo2.github.io/posts/training-an-llm-on-150k-discord-messages/

I found this post about an individual doing exactly what I am attempting to do, and will be using what they did as a framework for how I will proceed through my project. I plan to reuse minimal code from their version of the project, but I will likely use their code (either directly or as a reference) for Discord and LLM APIs so that I don't need to worry about learning said APIs. I will credit sources as they are used in my code.


TODO LIST:

x Create a github repo for this project.

x Write code to make and update a local SQLite db.

x Create a discord bot to use for scraping messages (and later to respond to messages using the AI).

x Write code to scrape discord messages and store them in a local db. Should only extract messages not already in db.

x Run scraper to gather my raw dataset.

- Write code to clean dataset (replace mentions & real names, remove links/images, etc)

- Write code to parse dataset from individual messages into conversations (possibly include LDA at this part).

- Write func to create a new dataset, using each conversation to create a prompt/input/response with the response being based on each of my existing messages. The collection of these prompt/input/repsonses will be the dataset with which we train the LLM.

- Install a Python package I can use to train an existing LLM. The alpaca dataset is my template.

- Hook up training data to LLM via Python script, train it for a few days and monitor progress. (Learning a LLM API will probably take a while, but I need to learn it with enough time remaining in order to have time to train).

- This might take a few weeks to finish training if all goes well.